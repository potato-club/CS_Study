# 로드 밸런싱 (Load Balancing)

---

## 개념

- 둘 이상의 컴퓨터 자원(CPU, 서버, 저장장치 등)에게 작업 부하(Load)를 **분산**하는 기술
- **클라이언트와 서버 사이에 위치한 Load Balancer**가 요청을 여러 서버로 적절히 분산

---

## 왜 로드 밸런싱이 필요한가?

- 웹 트래픽 증가 → 단일 서버로는 감당 불가
- 해결책:
  - **Scale-up**: 서버 성능 향상 → 비용 높고 유연성 낮음
  - **✅ Scale-out**: 여러 대의 서버로 분산 → 유연하고 무중단 서비스에 유리

→ 로드 밸런싱은 Scale-out 구조의 핵심 요소

---

## 로드 밸런싱 구조

```text
[Client] ⇄ [Load Balancer] ⇄ [Server 1, Server 2, ..., Server N]
```

- **Load Balancer**는 클라이언트 요청을 여러 서버로 적절히 분산
- 서비스의 안정성, 확장성, 무중단성 확보

---

## 서버 선택 방식

| 방식              | 설명 |
|-------------------|------|
| Round Robin     | 순서대로 서버에 요청 분배 (회전식) |
| Least Connections | 현재 연결 수가 가장 적은 서버 선택 |
| Source Hashing  | 클라이언트 IP 기반 해싱 → 특정 사용자는 동일 서버 연결 유지 가능 |

---

## 장애 대비

로드 밸런서 자체가 단일 장애 지점(SPOF)이 될 수 있음 → **로드 밸런서 이중화 필요**

- **Active-Passive 구조**
  - Active: 현재 요청 처리 중인 로드 밸런서
  - Passive: 대기 상태, Active 장애 발생 시 자동 전환

---

## 장점

- 서버 부하 분산 → 시스템 안정성 향상
- 수평적 확장(Scale-out) 용이
- 장애 시 무중단 서비스 유지
- 트래픽 급증에도 탄력적 대응 가능

---

## 📚 참고

- Nginx, HAProxy, AWS ELB (Elastic Load Balancer)
- Kubernetes Ingress Controller
- DNS Round Robin 방식
